{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.11"
    },
    "colab": {
      "name": "spam detection.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwjlGPU8ApfL"
      },
      "source": [
        "# Text Classification in scikit-learn(Spam Detection)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9CLp5-XApfk"
      },
      "source": [
        "## Part 1: Representing text as numerical data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "6-atcueoApfl"
      },
      "source": [
        "# example text for model training (SMS messages)\n",
        "simple_train = ['call you tonight', 'Call me a cab', 'please call me... PLEASE!']"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvgrvJ1BApfm"
      },
      "source": [
        "From the [scikit-learn documentation](http://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction):\n",
        "\n",
        "> Text Analysis is a major application field for machine learning algorithms. However the raw data, a sequence of symbols cannot be fed directly to the algorithms themselves as most of them expect **numerical feature vectors with a fixed size** rather than the **raw text documents with variable length**.\n",
        "\n",
        "We will use [CountVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) to \"convert text into a matrix of token counts\":"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "6emfh8yIApfm"
      },
      "source": [
        "# import and instantiate CountVectorizer (with the default parameters)\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "vect = CountVectorizer()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jmYVJpPEApfn",
        "outputId": "1375877f-e030-41ef-9542-5daa8177b8e3"
      },
      "source": [
        "# learn the 'vocabulary' of the training data (occurs in-place)\n",
        "vect.fit(simple_train)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
              "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
              "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
              "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
              "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "        tokenizer=None, vocabulary=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hryc1YffApfn",
        "outputId": "395f5e1d-ff2e-4567-e14f-5a6c53bcfb4d"
      },
      "source": [
        "# examine the fitted vocabulary\n",
        "vect.get_feature_names()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[u'cab', u'call', u'me', u'please', u'tonight', u'you']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bGh3p78uApfo",
        "outputId": "4674c59a-6fcd-4037-e842-3e433d8dfcd8"
      },
      "source": [
        "# transform training data into a 'document-term matrix'\n",
        "simple_train_dtm = vect.transform(simple_train)\n",
        "simple_train_dtm"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<3x6 sparse matrix of type '<type 'numpy.int64'>'\n",
              "\twith 9 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1IoVpSmkApfo",
        "outputId": "a867654c-13a5-4430-92e9-142b89d9e6ce"
      },
      "source": [
        "# convert sparse matrix to a dense matrix\n",
        "simple_train_dtm.toarray()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 1, 0, 0, 1, 1],\n",
              "       [1, 1, 1, 0, 0, 0],\n",
              "       [0, 1, 1, 2, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "id": "5ubvM-7DApfo",
        "outputId": "f1e9b231-712b-4692-9792-272485747768"
      },
      "source": [
        "# examine the vocabulary and document-term matrix together\n",
        "import pandas as pd\n",
        "pd.DataFrame(simple_train_dtm.toarray(), columns=vect.get_feature_names())"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   cab  call  me  please  tonight  you\n",
              "0    0     1   0       0        1    1\n",
              "1    1     1   1       0        0    0\n",
              "2    0     1   1       2        0    0"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cab</th>\n",
              "      <th>call</th>\n",
              "      <th>me</th>\n",
              "      <th>please</th>\n",
              "      <th>tonight</th>\n",
              "      <th>you</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9owfBQe6Apfp"
      },
      "source": [
        "From the [scikit-learn documentation](http://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction):\n",
        "\n",
        "> In this scheme, features and samples are defined as follows:\n",
        "\n",
        "> - Each individual token occurrence frequency (normalized or not) is treated as a **feature**.\n",
        "> - The vector of all the token frequencies for a given document is considered a multivariate **sample**.\n",
        "\n",
        "> A **corpus of documents** can thus be represented by a matrix with **one row per document** and **one column per token** (e.g. word) occurring in the corpus.\n",
        "\n",
        "> We call **vectorization** the general process of turning a collection of text documents into numerical feature vectors. This specific strategy (tokenization, counting and normalization) is called the **Bag of Words** or \"Bag of n-grams\" representation. Documents are described by word occurrences while completely ignoring the relative position information of the words in the document."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CpsmnSIIApfq",
        "outputId": "7927db71-8aab-41af-a450-39012bb84028"
      },
      "source": [
        "# check the type of the document-term matrix\n",
        "type(simple_train_dtm)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "scipy.sparse.csr.csr_matrix"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NGwcVGJfApfq",
        "outputId": "9e5a5e35-b491-4d3c-9318-b945f74df6c5"
      },
      "source": [
        "# examine the sparse matrix contents\n",
        "print(simple_train_dtm)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  (0, 1)\t1\n",
            "  (0, 4)\t1\n",
            "  (0, 5)\t1\n",
            "  (1, 0)\t1\n",
            "  (1, 1)\t1\n",
            "  (1, 2)\t1\n",
            "  (2, 1)\t1\n",
            "  (2, 2)\t1\n",
            "  (2, 3)\t2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXCCIvMEApfq"
      },
      "source": [
        "From the [scikit-learn documentation](http://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction):\n",
        "\n",
        "> As most documents will typically use a very small subset of the words used in the corpus, the resulting matrix will have **many feature values that are zeros** (typically more than 99% of them).\n",
        "\n",
        "> For instance, a collection of 10,000 short text documents (such as emails) will use a vocabulary with a size in the order of 100,000 unique words in total while each document will use 100 to 1000 unique words individually.\n",
        "\n",
        "> In order to be able to **store such a matrix in memory** but also to **speed up operations**, implementations will typically use a **sparse representation** such as the implementations available in the `scipy.sparse` package."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "hh0A4fLMApfr"
      },
      "source": [
        "# example text for model testing\n",
        "simple_test = [\"please don't call me\"]"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XclY5n1sApfr"
      },
      "source": [
        "In order to **make a prediction**, the new observation must have the **same features as the training observations**, both in number and meaning."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZB-Kh5rApfs",
        "outputId": "a258fcff-a7fe-4305-8b5f-7fb0200b601d"
      },
      "source": [
        "# transform testing data into a document-term matrix (using existing vocabulary)\n",
        "simple_test_dtm = vect.transform(simple_test)\n",
        "simple_test_dtm.toarray()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 1, 1, 1, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        },
        "id": "HdvzvVLYApfs",
        "outputId": "2e517cb8-187b-4f65-e320-22ba2ef3231c"
      },
      "source": [
        "# examine the vocabulary and document-term matrix together\n",
        "pd.DataFrame(simple_test_dtm.toarray(), columns=vect.get_feature_names())"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   cab  call  me  please  tonight  you\n",
              "0    0     1   1       1        0    0"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cab</th>\n",
              "      <th>call</th>\n",
              "      <th>me</th>\n",
              "      <th>please</th>\n",
              "      <th>tonight</th>\n",
              "      <th>you</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02zK8A4OApft"
      },
      "source": [
        "**Summary:**\n",
        "\n",
        "- `vect.fit(train)` **learns the vocabulary** of the training data\n",
        "- `vect.transform(train)` uses the **fitted vocabulary** to build a document-term matrix from the training data\n",
        "- `vect.transform(test)` uses the **fitted vocabulary** to build a document-term matrix from the testing data (and **ignores tokens** it hasn't seen before)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTmJmgS-Apfu"
      },
      "source": [
        "## Part 2: Reading a text-based dataset into pandas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "aOPkTJwgApfw"
      },
      "source": [
        "# read file into pandas using a relative path\n",
        "# path = 'data/sms.tsv'\n",
        "# sms = pd.read_table(path, header=None, names=['label', 'message'])"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbVxv2mqApfx",
        "outputId": "522d25d2-4f4d-4e9c-d278-407d388ce7a3"
      },
      "source": [
        "# read file into pandas from a URL\n",
        "url = \"https://raw.githubusercontent.com/pradeep-dsml/text-classification/main/spam%20detection/sms.tsv\"\n",
        "sms = pd.read_table(url, header=None, names=['label', 'message'])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:3: FutureWarning: read_table is deprecated, use read_csv instead, passing sep='\\t'.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RRH2LPX_Apfx",
        "outputId": "01c5f31b-65f3-458c-ab13-4a692ea77dc7"
      },
      "source": [
        "# examine the shape\n",
        "sms.shape"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5572, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "id": "J3OmG2wGApfy",
        "outputId": "2200584d-73b1-436b-ea9a-789274cdf7e9"
      },
      "source": [
        "# examine the first 10 rows\n",
        "sms.head(10)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  label                                            message\n",
              "0   ham  Go until jurong point, crazy.. Available only ...\n",
              "1   ham                      Ok lar... Joking wif u oni...\n",
              "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3   ham  U dun say so early hor... U c already then say...\n",
              "4   ham  Nah I don't think he goes to usf, he lives aro...\n",
              "5  spam  FreeMsg Hey there darling it's been 3 week's n...\n",
              "6   ham  Even my brother is not like to speak with me. ...\n",
              "7   ham  As per your request 'Melle Melle (Oru Minnamin...\n",
              "8  spam  WINNER!! As a valued network customer you have...\n",
              "9  spam  Had your mobile 11 months or more? U R entitle..."
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>message</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>spam</td>\n",
              "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>ham</td>\n",
              "      <td>Even my brother is not like to speak with me. ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>ham</td>\n",
              "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>spam</td>\n",
              "      <td>WINNER!! As a valued network customer you have...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>spam</td>\n",
              "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UAm1U_g0Apfy",
        "outputId": "648b460e-f24b-4ede-bbac-bbc6c395f25e"
      },
      "source": [
        "# examine the class distribution\n",
        "sms.label.value_counts()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ham     4825\n",
              "spam     747\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "rviMHDqMApfz"
      },
      "source": [
        "# convert label to a numerical variable\n",
        "sms['label_num'] = sms.label.map({'ham':0, 'spam':1})"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "id": "QMyG73PWApf0",
        "outputId": "29b8b3da-64bc-496b-ae8d-d4d3cba432db"
      },
      "source": [
        "# check that the conversion worked\n",
        "sms.head(10)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  label                                            message  label_num\n",
              "0   ham  Go until jurong point, crazy.. Available only ...          0\n",
              "1   ham                      Ok lar... Joking wif u oni...          0\n",
              "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...          1\n",
              "3   ham  U dun say so early hor... U c already then say...          0\n",
              "4   ham  Nah I don't think he goes to usf, he lives aro...          0\n",
              "5  spam  FreeMsg Hey there darling it's been 3 week's n...          1\n",
              "6   ham  Even my brother is not like to speak with me. ...          0\n",
              "7   ham  As per your request 'Melle Melle (Oru Minnamin...          0\n",
              "8  spam  WINNER!! As a valued network customer you have...          1\n",
              "9  spam  Had your mobile 11 months or more? U R entitle...          1"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>message</th>\n",
              "      <th>label_num</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>spam</td>\n",
              "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>ham</td>\n",
              "      <td>Even my brother is not like to speak with me. ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>ham</td>\n",
              "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>spam</td>\n",
              "      <td>WINNER!! As a valued network customer you have...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>spam</td>\n",
              "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbkUXVLxApf1",
        "outputId": "7b1e3ac6-eade-4f6b-85f7-64d1f811ef67"
      },
      "source": [
        "# how to define X and y (from the SMS data) for use with COUNTVECTORIZER\n",
        "X = sms.message\n",
        "y = sms.label_num\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5572,)\n",
            "(5572,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pjz9Zuj2Apf1",
        "outputId": "93e23910-34b8-4987-ffeb-75d87f51b799"
      },
      "source": [
        "# split X and y into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4179,)\n",
            "(1393,)\n",
            "(4179,)\n",
            "(1393,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5huewL2pApf2"
      },
      "source": [
        "## Part 3: Vectorizing our dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "_5iAunFxApf3"
      },
      "source": [
        "# instantiate the vectorizer\n",
        "vect = CountVectorizer()"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "NvUEO4beApf3"
      },
      "source": [
        "# learn training data vocabulary, then use it to create a document-term matrix\n",
        "vect.fit(X_train)\n",
        "X_train_dtm = vect.transform(X_train)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "nBO_lbB5Apf4"
      },
      "source": [
        "# equivalently: combine fit and transform into a single step\n",
        "X_train_dtm = vect.fit_transform(X_train)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Rj_kkyCApf5",
        "outputId": "f7c9dd18-972e-49eb-9556-b7581309f35b"
      },
      "source": [
        "# examine the document-term matrix\n",
        "X_train_dtm"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<4179x7456 sparse matrix of type '<type 'numpy.int64'>'\n",
              "\twith 55209 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Tlum6pFApf5",
        "outputId": "4b8d6c2f-7f0b-4892-fee7-f46e07834ca9"
      },
      "source": [
        "# transform testing data (using fitted vocabulary) into a document-term matrix\n",
        "X_test_dtm = vect.transform(X_test)\n",
        "X_test_dtm"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<1393x7456 sparse matrix of type '<type 'numpy.int64'>'\n",
              "\twith 17604 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TLweww1Apf6"
      },
      "source": [
        "## Part 4: Building and evaluating a model\n",
        "\n",
        "We will use [multinomial Naive Bayes](http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html):\n",
        "\n",
        "> The multinomial Naive Bayes classifier is suitable for classification with **discrete features** (e.g., word counts for text classification). The multinomial distribution normally requires integer feature counts. However, in practice, fractional counts such as tf-idf may also work."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "OjynaCMaApf6"
      },
      "source": [
        "# import and instantiate a Multinomial Naive Bayes model\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "nb = MultinomialNB()"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9x3lhBYApf6",
        "outputId": "6d0ef3dd-0e44-4d58-bfbe-e4ec54b26a91"
      },
      "source": [
        "# train the model using X_train_dtm (timing it with an IPython \"magic command\")\n",
        "%time nb.fit(X_train_dtm, y_train)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 3.91 ms, sys: 0 ns, total: 3.91 ms\n",
            "Wall time: 5.29 ms\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "M0HRiA_lApf7"
      },
      "source": [
        "# make class predictions for X_test_dtm\n",
        "y_pred_class = nb.predict(X_test_dtm)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WOrHmAFOApf7",
        "outputId": "52770f43-f894-4714-fe08-9b9f67755572"
      },
      "source": [
        "# calculate accuracy of class predictions\n",
        "from sklearn import metrics\n",
        "metrics.accuracy_score(y_test, y_pred_class)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9885139985642498"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qffPUXWdApf8",
        "outputId": "6b7c62e4-2a94-4c99-93f0-06280f9cb145"
      },
      "source": [
        "# print the confusion matrix\n",
        "metrics.confusion_matrix(y_test, y_pred_class)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1203,    5],\n",
              "       [  11,  174]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Am-sdqNAApf8"
      },
      "source": [
        "# print message text for the false positives (ham incorrectly classified as spam)\n"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "CtEoWIKwApf9"
      },
      "source": [
        "# print message text for the false negatives (spam incorrectly classified as ham)\n"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "zR63dibFApf-",
        "outputId": "64261196-3fb2-4a5c-d7cc-bc9c89236d0d"
      },
      "source": [
        "# example false negative\n",
        "X_test[3132]"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"LookAtMe!: Thanks for your purchase of a video clip from LookAtMe!, you've been charged 35p. Think you can do better? Why not send a video in a MMSto 32323.\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iA3KHj9PApf-",
        "outputId": "040e98c4-e067-4906-b260-bbd440d4183e"
      },
      "source": [
        "# calculate predicted probabilities for X_test_dtm (poorly calibrated)\n",
        "y_pred_prob = nb.predict_proba(X_test_dtm)[:, 1]\n",
        "y_pred_prob"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2.87744864e-03, 1.83488846e-05, 2.07301295e-03, ...,\n",
              "       1.09026171e-06, 1.00000000e+00, 3.98279868e-09])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_Hj7aQbApf_",
        "outputId": "e09740d7-262c-4937-c8b1-9a707abb9829"
      },
      "source": [
        "# calculate AUC\n",
        "metrics.roc_auc_score(y_test, y_pred_prob)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9866431000536962"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4OtEQS7HApf_"
      },
      "source": [
        "## Part 5: Comparing models\n",
        "\n",
        "We will compare multinomial Naive Bayes with [logistic regression](http://scikit-learn.org/stable/modules/linear_model.html#logistic-regression):\n",
        "\n",
        "> Logistic regression, despite its name, is a **linear model for classification** rather than regression. Logistic regression is also known in the literature as logit regression, maximum-entropy classification (MaxEnt) or the log-linear classifier. In this model, the probabilities describing the possible outcomes of a single trial are modeled using a logistic function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "rvw66uv-ApgA"
      },
      "source": [
        "# import and instantiate a logistic regression model\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "logreg = LogisticRegression()"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1WXpuvjCApgA",
        "outputId": "5e12a470-ddd1-44bb-d593-ac231876ef7a"
      },
      "source": [
        "# train the model using X_train_dtm\n",
        "%time logreg.fit(X_train_dtm, y_train)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 37.4 ms, sys: 138 Âµs, total: 37.6 ms\n",
            "Wall time: 44.5 ms\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python2.7/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
              "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
              "          tol=0.0001, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "V8Vljb38ApgB"
      },
      "source": [
        "# make class predictions for X_test_dtm\n",
        "y_pred_class = logreg.predict(X_test_dtm)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDtSBFuIApgB",
        "outputId": "78cce184-a8d6-4891-c2fd-348e9bca4873"
      },
      "source": [
        "# calculate predicted probabilities for X_test_dtm (well calibrated)\n",
        "y_pred_prob = logreg.predict_proba(X_test_dtm)[:, 1]\n",
        "y_pred_prob"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.01269556, 0.00347183, 0.00616517, ..., 0.03354907, 0.99725053,\n",
              "       0.00157706])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fVIZz46ApgC",
        "outputId": "0dcb39d6-be3a-47b6-d84c-55065729fda8"
      },
      "source": [
        "# calculate accuracy\n",
        "metrics.accuracy_score(y_test, y_pred_class)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9877961234745154"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4XDgqkfApgC",
        "outputId": "e4ac854e-4867-4b14-eb4a-5a33907ddc3d"
      },
      "source": [
        "# calculate AUC\n",
        "metrics.roc_auc_score(y_test, y_pred_prob)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9936817612314301"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QaVRbjvnApgJ"
      },
      "source": [
        "## Part 6: Tuning the vectorizer (discussion)\n",
        "\n",
        "Thus far, we have been using the default parameters of [CountVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CnP7_D4PApgJ",
        "outputId": "d937edba-6b5f-45db-bb70-46e183b85556"
      },
      "source": [
        "# show default parameters for CountVectorizer\n",
        "vect"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
              "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
              "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
              "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
              "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "        tokenizer=None, vocabulary=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zaQ1RWPHApgK"
      },
      "source": [
        "However, the vectorizer is worth tuning, just like a model is worth tuning! Here are a few parameters that you might want to tune:\n",
        "\n",
        "- **stop_words:** string {'english'}, list, or None (default)\n",
        "    - If 'english', a built-in stop word list for English is used.\n",
        "    - If a list, that list is assumed to contain stop words, all of which will be removed from the resulting tokens.\n",
        "    - If None, no stop words will be used."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "0wo4rht-ApgK"
      },
      "source": [
        "# remove English stop words\n",
        "vect = CountVectorizer(stop_words='english')"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPecYTMuApgK"
      },
      "source": [
        "- **ngram_range:** tuple (min_n, max_n), default=(1, 1)\n",
        "    - The lower and upper boundary of the range of n-values for different n-grams to be extracted.\n",
        "    - All values of n such that min_n <= n <= max_n will be used."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "8HOOLNNUApgL"
      },
      "source": [
        "# include 1-grams and 2-grams\n",
        "vect = CountVectorizer(ngram_range=(1, 2))"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhGX3zw2ApgL"
      },
      "source": [
        "- **max_df:** float in range [0.0, 1.0] or int, default=1.0\n",
        "    - When building the vocabulary, ignore terms that have a document frequency strictly higher than the given threshold (corpus-specific stop words).\n",
        "    - If float, the parameter represents a proportion of documents.\n",
        "    - If integer, the parameter represents an absolute count."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "6Ujt61KqApgM"
      },
      "source": [
        "# ignore terms that appear in more than 50% of the documents\n",
        "vect = CountVectorizer(max_df=0.5)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aX93v2OsApgM"
      },
      "source": [
        "- **min_df:** float in range [0.0, 1.0] or int, default=1\n",
        "    - When building the vocabulary, ignore terms that have a document frequency strictly lower than the given threshold. (This value is also called \"cut-off\" in the literature.)\n",
        "    - If float, the parameter represents a proportion of documents.\n",
        "    - If integer, the parameter represents an absolute count."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "cE-Gy0wZApgN"
      },
      "source": [
        "# only keep terms that appear in at least 2 documents\n",
        "vect = CountVectorizer(min_df=2)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4HK6yK37ApgN"
      },
      "source": [
        "**Guidelines for tuning CountVectorizer:**\n",
        "\n",
        "- Use your knowledge of the **problem** and the **text**, and your understanding of the **tuning parameters**, to help you decide what parameters to tune and how to tune them.\n",
        "- **Experiment**, and let the data tell you the best approach!"
      ]
    }
  ]
}